# Set up your BigQuery account

As you’ve been learning, BigQuery is a database you can use to access, explore, and analyze data from many sources. Now, you’ll begin using BigQuery, which will help you gain SQL knowledge by typing out commands and troubleshooting errors. This reading will guide you through the process of setting up your very own BigQuery account.

**Note:** Working with BigQuery is not a requirement of this program. Additional resources for other SQL database platforms are also provided at the end of this reading if you choose to use them instead.

## BigQuery account options

BigQuery offers a variety of account tiers to cater to various user needs and has two free-of-charge entry points, a sandbox account and a free-of-charge trial account. These options allow you to explore the program before selecting the best choice to suit your needs. A sandbox account allows you to practice writing queries and to explore public datasets free of charge, but it has [quotas and limits](https://cloud.google.com/bigquery/quotas), as well as some additional [restrictions](https://cloud.google.com/bigquery/docs/sandbox#limits). If you prefer to use BigQuery with the standard limits, you can set up a free-of-charge trial account instead. The free-of-charge trial is a trial period prior to paying for a subscription. In this instance, there is no automatic charge, but you will be asked for payment information when you create the account.

This reading provides instructions for setting up either account type.  An effective first step is to begin with a sandbox account and switch to a free-of-charge trial account when needed to run the SQL presented upcoming courses.

### **Sandbox account**

The sandbox account is available at no cost, and anyone with a Google account can use it. However, it does have some limitations. For instance, you are limited to a maximum of 12 projects at a time. This means that, to create a 13th project, you'll need to delete one of your existing 12 projects. Additionally, the sandbox account doesn't support all operations you’ll do in this program. For example, there are limits on the amount of data you can process and you can’t insert new records into a database or update the values of existing records. However, a sandbox account is perfect for most program activities, including all of the activities in this course. Additionally, you can convert your sandbox account into a free-of-charge trial account at any time.

**Set up your sandbox account**

To set up a sandbox account:

1. Visit the [BigQuery sandbox documentation](https://cloud.google.com/bigquery/docs/sandbox#limits) page.
2. Log in to your preferred Google account by selecting the profile icon in the BigQuery menu bar.
3. Select the **Go to BigQuery** button on the documentation page.
4. You'll be prompted to select your country and read the terms of service agreement.
5. This will bring you to the **SQL Workspace**, where you'll be conducting upcoming activities. By default, BigQuery creates a project for you.

After you set up your account, the name of the project will be in the banner in your BigQuery console.

### **Free-of-charge trial**

If you wish to explore more of BigQuery's capabilities with fewer limitations, consider the Google Cloud Free Trial. It provides you with $300 in credit for Google Cloud usage during the first 90 days. If you're primarily using BigQuery for SQL queries, you're unlikely to come close to this spending limit. After you've used up the $300 credit or after 90 days, your free trial will expire, and you will only be able to use this account if you pay to do so. Google won't automatically charge your payment method when the trial ends. However, you'll need to set up a payment option with Google Cloud. This means that you’ll need to enter your financial information. Rest assured, it won't charge you unless you consciously opt to upgrade to a paid account. If you're uncomfortable providing payment information, don't worry; you can use the BigQuery sandbox account instead.

**Set up your free-of-charge trial**

1. Go to the [BigQuery](https://cloud.google.com/bigquery) page.
2. Select **Try BigQuery free**.
3. Log in using your Google email, or create an account free of charge if you don't have one. [Click here](https://cloud.google.com/bigquery?utm_source=google&utm_medium=cpc&utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1605212&utm_content=text-ad-none-any-DEV_c-CRE_665665924750-ADGP_Hybrid+%7C+BKWS+-+MIX+%7C+Txt_BigQuery-KWID_43700077225652770-kwd-274188433361&utm_term=KW_bigquery%20account-ST_bigquery+account&gclid=CjwKCAjwkNOpBhBEEiwAb3MvvYQXjIQ4TRnkITJoSXz7DFez4T-XKPG5IpfKmxUg2iHPEmiJBNQByhoCLVgQAvD_BwE&gclsrc=aw.ds) to create an account.
4. Select your country, a description of your organization or needs, and the checkbox to accept the terms of service, Then select **CONTINUE**.
5. Enter your billing information and select **START MY FREE TRIAL**.

After you set up your account, your first project, titled **My First Project** will be in the banner.

![Image of a Google Cloud dashboard with text written that says “My First Project”.](./assets/BQ-1.jpeg)

### **Transferring between BigQuery accounts**

With either a sandbox or free-of-charge trial account, you have the flexibility to upgrade to a paid account at any time. If you upgrade, all your existing projects will be retained and transferred to your new account. If you started with a free-of-charge trial, but choose not to upgrade when it ends, you can switch to a sandbox account. However, note that projects from your trial won't transfer to your sandbox. Essentially, creating a sandbox is like starting from scratch.

## Get started with other databases (if not using BigQuery)

It’s easiest to follow along with the course activities if you use BigQuery, but you may use other SQL platforms, if you prefer. If you decide to practice SQL queries on other database platforms, here are some resources to get started:

* [Getting Started with MySQL](https://dev.mysql.com/doc/mysql-getting-started/en/)
* [Getting Started with Microsoft SQL Server](https://docs.microsoft.com/en-us/sql/relational-databases/tutorial-getting-started-with-the-database-engine?view=sql-server-ver15)
* [Getting Started with PostgreSQL](https://www.postgresql.org/docs/10/tutorial-start.html)
* [Getting Started with SQLite](https://www.sqlite.org/quickstart.html)

## Key takeaways

BigQuery offers multiple account options. Keep the following in mind when you choose an account type:

* **Account tiers:** BigQuery provides various account tiers to cater to a wide range of user requirements. Whether you're starting with a sandbox account or exploring a paid account with the free-of-charge trial option, BigQuery offers flexibility to choose the option that aligns best with your needs and budget.
* **Sandbox limitations:** While a sandbox account is a great starting point, it comes with some limitations, such as a cap on the number of projects and restrictions on data manipulation operations like inserting or updating records, which you will encounter later in this program. Be aware of these limitations if you choose to work through this course using a sandbox account.
* **Easy setup and upgrades:** Getting started with any BigQuery account type is quick and easy. And if your needs evolve, you have the flexibility to modify your account status at any time. Additionally, projects can be retained even when transitioning between account types.

Choose the right BigQuery account type to match your specific needs and adapt as your requirements change!

# Get started with BigQuery

BigQuery is a data warehouse on the Google Cloud Platform used to query and filter large datasets, aggregate results, and perform complex operations. Throughout this program, you’re going to use BigQuery to practice your SQL skills and collect, prepare, and analyze data. At this point, you have set up your own account. Now, explore some of the important elements of the SQL workspace. This will prepare you for the upcoming activities in which you will use BigQuery. Note that BigQuery updates its interface frequently, so your console might be slightly different from what is described in this reading. That’s okay; use your troubleshooting skills to find what you need!

## Log in to BigQuery

When you log in to BigQuery using the landing page, you will automatically open your project space. This is a high-level overview of your project, including the project information and the current resources being used. From here, you can check your recent activity.

![Bigquery project dashboard page](./assets/BQ-2.png)

Navigate to your project’s BigQuery Studio by selecting BigQuery from the navigation menu and BigQuery Studio from the dropdown menu.

![BigQuery navigation menu open with the BigQuery Studio option selected.](./assets/BQ-3.png)

## BiqQuery Studio components

Once you have navigated to BigQuery from the project space, most of the major components of the BigQuery console will be present: the **Navigation** pane, the **Explorer** pane, and the **SQL Workspace**.

![The BigQuery Console with the three major menus open: the Navigation pane, the Explorer pane, and the SQL Workspace](./assets/BQ-4.png)

### The Navigation pane

On the console page, find the **Navigation** pane. This is how you navigate from the project space to the BigQuery tool. This menu also contains a list of other Google Cloud Project (GCP) data tools. During this program, you will focus on BigQuery, but it’s useful to understand that the GCP has a collection of connected tools data professionals use every day.

### The Explorer pane

The **Explorer** pane lists your current projects and any starred projects you have added to your console. It’s also where you’ll find the **+ ADD** button, which you can use to add datasets.

![The + Add button in the Explorer pane.](./assets/BQ-5.png)

This button opens the **Add** dialog that allows you to open or import a variety of datasets.

![The Add dialog, displaying options to search for a data source or add popular or additional data sources.](./assets/BQ-6.png)

### Add Public Datasets

BigQuery offers a variety of public datasets from the Google Cloud Public Dataset Program. Scroll down the **Add** dialog to the **Public Datasets** option.

![The Public Datasets option in the Add dialog.](./assets/BQ-7.png)

Select **Public Datasets**. This takes you to the **Public Datasets Marketplace**, where you can search for and select public datasets to add to your BigQuery console. For example, search for the "noaa lightning" dataset in the Marketplace search bar. When you search for this dataset, you will find NOAA’s Cloud-to-Ground Lightning Strikes data.

![The BigQuery Console showing NOAA’s Cloud to Ground Lightning Strikes as a search result in Datasets.](./assets/BQ-8.png)

Select the dataset to read its description. Select **View dataset** to create a tab of the dataset’s information within the SQL workspace.

![The noaa_lightning dataset in a tab in the SQL workspace. The SQL workspace displays the dataset’s information.](./assets/BQ-9.png)The Explorer Pane lists the noaa_lightning and other public datasets.

### Star and examine Public Datasets

You added the public noaa_lightning dataset to your BigQuery Workspace, so the **Explorer** pane displays the noaa_lightning dataset, along with the list of other public datasets. These datasets are nested under bigquery-public-data. Star bigquery-public-data by navigating to the top of the **Explorer** pane and selecting the star next to bigquery-public-data.

![The bigquery-public-dataset with the star filled in, indicating it has been starred.](./assets/BQ-10.png)

Starring bigquery-public-data will enable you to search for and add public datasets by scrolling in the **Explorer** pane or by searching for them in the **Explorer** search bar.

For example, you might want to select a different public dataset. If you select the second dataset, "austin_311," it will expand to list the table stored in it, “311_service_requests.”

![](./assets/BQ-11.png)The Explorer pane with the “bigquery-public data” and “austin_311” datasets expanded, revealing the “311_service_requests” table

When you select a table, its information is displayed in the SQL Workspace. Select the 311_service_requests table to examine several tabs that describe it, including:

* **Schema**, which displays the column names in the dataset
* **Details**, which contains additional metadata, such as the creation date of the dataset
* **Preview**, which shows the first rows from the dataset

![The table preview of the 311_service_requests table with the Schema tab open](./assets/BQ-12.png)

Additionally, you can select the **Query** button from the menu bar in the SQL Workspace to query this table.

### The SQL Workspace

The final menu pane in your console is the SQL Workspace. This is where you will actually write and execute queries in BigQuery.

![Blank query editor tab](./assets/BQ-13.png)

The SQL Workspace also gives you access to your personal and project history, which stores a record of the queries you’ve run. This can be useful if you want to return to a query to run it again or use part of it in another query.

## Upload your data

In addition to offering access to public datasets, BigQuery also gives you the ability to upload your own data directly into your workspace. Access this feature by opening the **+ ADD** menu again or by clicking the three vertical dots next to your project’s name in the Explorer pane. This will give you the option to create your own dataset and upload your own tables. You will have the opportunity to upload your own data in an upcoming activity to practice using this feature!

![Gemini logo](./assets/BQ-14.png)

Within BigQuery you’ll also find powerful AI tools to help you with your code—tools like Gemini Cloud Assist and the SQL generation tool. These tools function as assistants that can help analyze code and find errors, suggest modifications, and also interact in a conversational way to answer many other questions, whether they’re technical or more conceptual.

To enable Gemini Cloud Assist, find the Gemini icon in the upper-right corner of the BigQuery console to toggle a Gemini Cloud Assist panel. Here, you can query Gemini using natural language.

To use the SQL generation tool within the SQL editor itself, locate the magic wand icon at the upper-left corner of the SQL query window. Clicking here will open a window where you can ask Gemini to generate SQL queries for your data.

While features like AI-powered SQL generation, code completion, and data insights within BigQuery can accelerate your workflow, please remember that this technology is still evolving. The suggestions, code, or explanations provided may not always be perfectly accurate, optimal, or secure. Always review and validate any AI-generated output before executing queries or relying on the information. Treat the AI assistance as a helpful co-pilot, but maintain oversight and responsibility for your final queries and analysis.

![Screenshot of the BigQuery SQL editor, highlighting icons for Gemini Cloud Assist and SQL generation tool.](./assets/BQ-15.png)

For more information on these tools and detailed walkthroughs refer to the following pages:

[Gemini in BigQuery overview](https://cloud.google.com/gemini/docs/bigquery/overview)

[Write queries with Gemini assistance](https://cloud.google.com/bigquery/docs/write-sql-gemini

# Step-by-Step: BigQuery in action

This reading provides you with the steps the instructor performs in the following video, [BigQuery in action](https://www.coursera.org/learn/data-preparation/lecture/H877e/bigquery-in-action). The video focuses on how to create a query to view a small section of data from a large dataset.

Keep this guide open as you watch the video. It can serve as a helpful reference if you need additional context or clarification while following the video steps. This is not a graded activity, but you can complete these steps to practice the skills demonstrated in the video.

## What you'll need

To follow along with the examples in this video, log in to your BigQuery account and follow the instructions to star bigquery-public-data in **The Explorer pane** section of the previous reading, [Get Started with BigQuery](https://www.coursera.org/learn/data-preparation/supplement/7ctZ8/get-started-with-bigquery).

## Example 1: Preview a section from a table viewer

A database is a collection of data stored in a computer system. Query languages such as SQL enable communication between databases and data analysts. You discovered earlier that a relational database is made up of several tables that may be joined together to create relationships. Primary and foreign keys serve as representations of these relationships. To extract data from these tables, data analysts use queries. To learn more about that, explore BigQuery in action:

1. Log in to [BigQuery](https://console.cloud.google.com/bigquery "Link to BigQuery console") and go to your console. You should find the **Welcome to your SQL Workspace!** landing page open. Select **COMPOSE A NEW QUERY** In the Bigquery console. Make sure that no tabs are open so that the entire workspace is displayed, including the **Explorer** pane.
2. Enter **sunroof** in the search bar. In the search results, expand **sunroof_solar** and then select the **solar_potential_by_postal_code** dataset.
3. Observe the **Schema tab** of the **Explorer** pane to explore the table fields.
4. Select the **Preview** tab to view the regions, states, yearly sunlight, and more.

![A screenshot of the BigQuery interface with the COMPOSE A NEW QUERY button visible](./assets/BQ-17.png)

## Example 2: Writing a query

In order to view the entire dataset, you will need to write a query.

1. The first step is finding out the complete, correct path to the table you want to work with. Select the **ellipses** (three vertical dots) by the dataset solar_potential_by_postal_code, then select **Query**. A new tab will populate on your screen. Select the tab. The path to the table should be written inside two backticks.
2. Select the full path by highlighting the text including the backticks and copy it.  (**Note:** You can also get the full path to the project, database, and table directly by clicking the ellipses next to the table's name in the **Explorer** panel on the left and selecting **Copy ID**.)
3. Now, click on the **plus sign** to create a new query. Notice that BigQuery doesn’t automatically generate a SELECT statement in this window. Enter **SELECT** and add a space after it.
4. Put an asterisk * after SELECT to indicate you want to return the entire dataset. The asterisk lets the database know to include all columns. Without this shortcut, you would have to manually enter every column name!
5. Next, press the **Enter/Return** key and enter **FROM** on the second line. FROM indicates where the data is coming from. After FROM, add another space.
6. Paste in the path to the table that you copied earlier. It will read `bigquery-public-data.sunroof_solar.solar_potential_by_postal_code`
7. Execute the query by selecting the **RUN** button.

![The BigQuery editor showing the SELECT query at the top and the results from running the query at the bottom](./assets/BQ-18.png)

**Important!**

Many of the public databases on BigQuery are living records and, as such, are periodically updated with new data. Throughout this course (and others in this certificate program), if your results differ from those you encounter in videos or screenshots, there's a good chance it is due to a data refresh. You can verify when a table has been refreshed by selecting it from the **Explorer** panel and clicking **Details**. You'll find the date the table was created, when it was last modified, as well as other useful information.

![Screenshot of "Details" tab for solar potential by postal code table. It was created Nov. 16, 2017 & modified Nov. 12, 2021.](./assets/BQ-19.png)

## Example 3: Use SQL to view a piece of data

If the project doesn’t require every field to be completed, you can use SQL to see a particular piece, or pieces, of data. To do this, specify a certain column name in the query.

1. For example, you might only need data from Pennsylvania. You’d begin your query the same way you just did in the previous examples: Click on the **plus sign**, enter SELECT, add a space, an asterisk (*), and then press **Enter/Return**.
2. Enter **FROM** and then paste `bigquery-public-data.sunroof_solar.solar_potential_by_postal_code`. Press **Enter/Return**.
3. This time, add WHERE. It will be on the same line as the FROM statement. Add a space and enter state_name with a space before state and a space after name. state_name is a column name in the table.
4. Because you only want data from Pennsylvania, add = and 'Pennsylvania' on the same line as state_name. In SQL, single quotes represent the beginning and ending of a string.
5. Execute the query with the **RUN** button.
6. Review the data on solar potential for Pennsylvania. Scroll through the query results.

Keep in mind that SQL queries can be written in a lot of different ways and still return the same results. You might discover other ways to write these queries!

# In-depth guide: SQL best practices

Save this reading for future reference. Feel free to download a .pdf version of this reading below:

[DAC3-In-depth-guide_-SQL-best-practices.pdf PDF File](https://www.coursera.org/api/rest/v1/asset/download/pdf/UwaGyGQoRLu9Dw_8BLUTiQ?pageStart=&pageEnd=)

These best practices include guidelines for entering SQL queries, developing documentation, and examples that demonstrate these practices. This is a great resource to have handy when you are using SQL yourself; you can just go straight to the relevant section to review these practices. Think of it like a SQL field guide!

## Capitalization and case sensitivity

With SQL, capitalization usually doesn’t matter. You could enter SELECT or select or SeLeCT. They all work! But if you use capitalization as part of a consistent style your queries will  look more professional.

To enter SQL queries like a pro, it is always a good idea to use all caps for clause starters (e.g. SELECT, FROM, WHERE, etc.). Functions should also be in all caps (e.g. SUM()). Column names should be all lowercase (refer to the section on snake_case later in this guide). Table names should be in CamelCase (refer to the section on CamelCase later in this guide). This helps keep your queries consistent and easier to read while not impacting the data that will be pulled when you run them. The only time that capitalization does matter is when it is inside quotes (more on quotes below).

Vendors of SQL databases may use slightly different variations of SQL. These variations are called **SQL dialects**. Some SQL dialects are case sensitive. BigQuery is one of them. Vertica is another. But most, like MySQL, PostgreSQL, and SQL Server, aren’t case sensitive. This means if you searched for country_code = ‘us’, it will return all entries that have 'us', 'uS', 'Us', and 'US'. This isn’t the case with BigQuery. BigQuery is case sensitive, so that same search would only return entries where the country_code is exactly 'us'. If the country_code is 'US', BigQuery wouldn’t return those entries as part of your result.

## Single or double quotes: '' or " "

For the most part, it also doesn’t matter if you use single quotes ' ' or double quotes " " when referring to strings. For example, SELECT is a clause starter. If you put SELECT in quotes like 'SELECT' or "SELECT", then SQL will treat it as a text string. Your query will return an error because your query needs a SELECT clause.

But there are two situations where it does matter what kind of quotes you use:

1. When you want strings to be identifiable in *any* SQL dialect
2. When your string contains an apostrophe or quotation marks

Within each SQL dialect there are rules for what is accepted and what isn’t. But a general rule across almost all SQL dialects is to use single quotes for strings. This helps get rid of a lot of confusion. So if we want to reference the country US in a WHERE clause (e.g. country_code = 'US'), then use single quotes around the string 'US'.

The second situation is when your string has quotes inside it. Suppose you have a column favorite_food in a table called FavoriteFoods and the other column corresponds to each friend.


| friend          | favorite_food   |
| ----------------- | ----------------- |
| Rachel DeSantos | Shepherd’s pie |
| Sujin Lee       | Tacos           |
| Najil Okoro     | Spanish paella  |

You might notice how Rachel’s favorite food contains an apostrophe. If you were to use single quotes in a WHERE clause to find the friend who has this favorite food, it would look like this:

```sql
SELECT
      friend
FROM
      FavoriteFoods
WHERE
      favorite_food = 'Shepherd's pie'
```

**This won’t work.** If you run this query, you will get an error in return. This is because SQL recognizes a text string as something that starts with a quote ' and ends with another quote '. So in the bad query above,  SQL thinks that the favorite_food you are looking for is 'Shepherd', because the apostrophe in Shepherd**'**s ends the string.

Generally speaking, this should be the only time you would use double quotes instead of single quotes. So your query would look like this instead:

```sql
SELECT
      friend
FROM
      FavoriteFoods
WHERE
      favorite_food = "Shepherd's pie"
```

SQL understands text strings as either starting with a single quote ' or double quote ". Since this string starts with double quotes, SQL will expect another double quote to signal the end of the string. This keeps the apostrophe safe, so it will return "Shepherd's pie" and not 'Shepherd'.

## Comments as reminders

As you get more comfortable with SQL, you will be able to read and understand queries at a glance. But it never hurts to have comments in the query to remind yourself of what you are trying to do. And if you share your query, it also helps others understand it.

For example:

```sql
--This is an important query used later to join with the accounts table
SELECT
      rowkey, -key used to join with account_id
      Info.date, -date is in spring format YYYY-MM-DD HH:MM:SS
      Info.code -e.g. 'pub-###'
FROM
      Publishers
```

You can use # in place of the two dashes, --, in the above query but keep in mind that # isn’t recognized in all SQL dialects (MySQL doesn’t recognize #). So it is best to use -- and be consistent with it. When you add a comment to a query using --, the database query engine will ignore everything in the same line after --. It will continue to process the query starting on the next line.

## snake_case names for columns

It is important to always make sure that the output of your query has easy-to-understand names. If you create a new column (say from a calculation or from concatenating new fields), the new column will receive a generic default name (e.g. f0). For example:

```sql
SELECT
      SUM(tickets),
      COUNT(tickets),
      SUM(tickets) AS total_tickets,
      COUNT(tickets) AS number_of_purchases
FROM
      Purchases
```

Results are:


| f0 | f1 | total_tickets | number_of_purchases |
| ---- | ---- | --------------- | --------------------- |
| 8  | 4  | 8             | 4                   |

The first two columns are named f0 and f1 because they weren’t named in the above query. SQL defaults to f0, f1, f2, f3, and so on. We named the last two columns total_tickets and number_of_purchases so these column names show up in the query results. This is why it is always good to give your columns useful names, especially when using functions. After running your query, you want to be able to quickly understand your results, like the last two columns we described in the example.

On top of that, you might notice how the column names have an underscore between the words. Names should never have spaces in them. If total_tickets had a space and looked like total tickets then SQL would throw a syntax error because it wouldn't know what to do with the second word (tickets). So, spaces are bad in SQL names. Never use spaces.

The best practice is to use snake_case. This means that 'total tickets', which has a space between the two words, should be entered as total_tickets with an underscore instead of a space.

## CamelCase names for tables

You can also use CamelCase capitalization when naming your table. CamelCase capitalization means that you capitalize the start of each word, like a two-humped (Bactrian) camel. So the table TicketsByOccasion uses CamelCase capitalization. Please note that the capitalization of the first word in CamelCase is *optional; *camelCase is also used. Some people differentiate between the two styles by calling CamelCase,** **PascalCase, and reserving camelCase for when the first word isn't capitalized, like a one-humped (Dromedary) camel; for example, ticketsByOccasion.

At the end of the day, CamelCase is a style choice. There are other ways you can name your tables, including:

* All lower or upper case, like ticketsbyoccasion or TICKETSBYOCCASION
* With snake_case,  like tickets_by_occasion

Keep in mind, the option with all lowercase or uppercase letters can make it difficult to read your table name, so it isn’t recommended for professional use.

The second option, snake_case, is technically okay. With words separated by underscores, your table name is easy to read, but it can get very long because you are adding the underscores. It also takes more time to enter. If you use this table a lot, it can become a chore.

In summary, it is up to you to use snake_case or CamelCase when creating table names. Just make sure your table name is easy to read and consistent. Also be sure to find out if your company has a preferred way of naming their tables. If they do, always go with their naming convention for consistency.

## Indentation

As a general rule, you want to keep the length of each line in a query <= 100 characters. This makes your queries easy to read. For example, check out this query with a line with >100 characters:

```sql
SELECT 
CASE WHEN genre = 'horror' THEN 'Will not watch' WHEN genre = 'documentary' 
THEN 'Will watch alone' ELSE 'Watch with others' END AS 
watch_category, COUNT(movie_title) AS number_of_movies
    FROM
        MovieTheater
    GROUP BY
        1
```

This query is hard to read and just as hard to troubleshoot or edit. Now, here is a query where we stick to the <= 100 character rule:

```sql
SELECT 
    CASE
        WHEN genre = 'horror' THEN 'Will not watch' 
        WHEN genre = 'documentary' THEN 'Will watch alone' 
        ELSE 'Watch with others' 
        END AS watch_category, COUNT(movie_title) AS number_of_movies
FROM
    MovieTheater
GROUP BY
    1
```

Now it is much easier to understand what you are trying to do in the SELECT clause. Sure, both queries will run without a problem because indentation doesn’t matter in SQL. But proper indentation is still important to keep lines short. And it will be valued by anyone reading your query, including yourself!

## Multi-line comments

If you make comments that take up multiple lines, you can use -- for each line. Or, if you have more than two lines of comments, it might be cleaner and easier is to use /* to start the comment and */ to close the comment. For example, you can use the -- method like below:

```sql
-- Date: September 15, 2020 
-- Analyst: Jazmin Cisneros 
-- Goal: Count the number of rows in the table 
SELECT 
	COUNT(*) number of rows -- the * stands for all so count all 
FROM
 	table
```

Or, you can use the /* */ method like below:

```sql
/* Date: September 15, 2020 
Analyst: Jazmin Cisneros 
Goal: Count the number of rows in the table 
*/
SELECT 
	COUNT(*) number of rows -- the * stands for all so count all 
FROM
 	table
```

In SQL, it doesn’t matter which method you use. SQL ignores comments regardless of what you use: #, --, or /* and */. So it is up to you and your personal preference. The /* and  */ method for multi-line comments usually looks cleaner and helps separate the comments from the query. But there isn’t one right or wrong method.

## SQL text editors

When you join a company, you can expect each company to use their own SQL platform and SQL dialect. The SQL platform they use (e.g. BigQuery, MySQL, or SQL Server) is where you will enter and run your SQL queries. But keep in mind that not all SQL platforms provide native script editors to enter SQL code. SQL text editors give you an interface where you can enter your SQL queries in an easier and color-coded way. In fact, all of the code we have been working with so far was entered with an SQL text editor!

## Examples with Sublime Text

If your SQL platform doesn’t have color coding, you might want to think about using a text editor like [Sublime Text](https://www.sublimetext.com/ "This link takes you to the Sublime Text home page.") or [Atom](https://atom.io/ "This link takes you to the Atom home page."). This section shows how SQL is displayed in Sublime Text. Here is a query in Sublime Text:

![](./assets/BQ-20.png)

With Sublime Text, you can also do advanced editing like deleting indents across multiple lines at the same time. For example, suppose your query somehow had indents in the wrong places and looked like this:

![](./assets/BQ-21.png)

This is really hard to read, so you will want to eliminate those indents and start over. In a regular SQL platform, you would have to go into each line and press BACKSPACE to delete each indent per line. But in Sublime, you can get rid of all the indents at the same time by selecting all lines and pressing Command (or CTRL in Windows) + [. This eliminates indents from every line. Then you can select the lines that you want to indent (i.e., lines 2, 4, and 6) by pressing the Command key (or the CTRL key in Windows) and selecting those lines. Then while still holding down the Command key (or the CTRL key in Windows), press  ] to indent lines 2, 4, and 6 at the same time. This will clean up your query and make it look like this instead:

![](./assets/BQ-22.png)

Sublime Text also supports regular expressions. **Regular expressions** (or **regex**) can be used to search for and replace string patterns in queries. We won’t cover regular expressions here, but you might want to learn more about them on your own because they are a very powerful tool.
